{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6ba4dc3",
   "metadata": {},
   "source": [
    "# Polymer End of Life Approximation\n",
    "\n",
    "This notebook very roughly approximates the volume of polymers reaching end of life in each region within the [Global Plastics AI Policy Tool](https://global-plastics-tool.org/) per year. It does this by distributing waste in each fate proportionally to the size of each sector at the time of waste generation. Having attributed waste by sector, a static matrix converts to polymers which are then summed across sectors.\n",
    "\n",
    "Note that this is a highly approximate estimation. This notebook discusses limitations of this approach and alternatives after generating the output CSV file. See discussion below.\n",
    "\n",
    "Uses data from [10.1126/science.adr3837](https://www.science.org/doi/10.1126/science.adr3837): A. Samuel Pottinger et al. Pathways to reduce global plastic waste mismanagement and greenhouse gas emissions by 2050. Science 386, 1168-1173 (2024)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2081c3c",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Setup\n",
    "\n",
    "We first download and prepare to process the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26dee1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import itertools\n",
    "\n",
    "import requests\n",
    "import toolz.itertoolz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143de18b",
   "metadata": {},
   "source": [
    "### Constants\n",
    "\n",
    "This script iterates across regions, fates, polymers, sectors, and simulation years. As a convienence, these are provided as constants after importing the required libraries along with the service URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68c46ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "REGIONS = ['china', 'eu30', 'na', 'mw']\n",
    "\n",
    "FATES = [\n",
    "    'eolLandfillMT',\n",
    "    'eolIncinerationMT',\n",
    "    'eolMismanagedMT',\n",
    "    'eolRecyclingMT'\n",
    "]\n",
    "\n",
    "POLYMERS = [\n",
    "    'ldpe',\n",
    "    'hdpe',\n",
    "    'pp',\n",
    "    'ps',\n",
    "    'pvc',\n",
    "    'pet',\n",
    "    'pur',\n",
    "    'other thermoplastics',\n",
    "    'other thermosets'\n",
    "]\n",
    "\n",
    "SECTORS = [\n",
    "    'consumptionTransportationMT',\n",
    "    'consumptionPackagingMT',\n",
    "    'consumptionConstructionMT',\n",
    "    'consumptionElectronicMT',\n",
    "    'consumptionHouseholdLeisureSportsMT',\n",
    "    'consumptionAgricultureMT',\n",
    "    'consumptionOtherMT'\n",
    "]\n",
    "\n",
    "\n",
    "YEARS = list(range(2011, 2051))\n",
    "\n",
    "SERVICE_FILES_URL = 'https://global-plastics-tool.org/data/%s'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599aa6ff",
   "metadata": {},
   "source": [
    "We provide these values as Majority World (MW) instead of Rest of World (ROW) and North America (NA) instead of NAFTA. These labels encompass the same parts of the world in either labeling convention. That said, we encourage use of MW and NA. Alternative data exports with \"legacy\" names can be found in [the tool data directory](https://global-plastics-tool.org/data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b9edb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEGACY_REGION_MAP = {\n",
    "    'china': 'china',\n",
    "    'eu30': 'eu30',\n",
    "    'nafta': 'na',\n",
    "    'row': 'mw'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70ec7d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_region(target):\n",
    "    target_lower = target.strip().lower()\n",
    "    return LEGACY_REGION_MAP.get(target_lower, target_lower)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd63721",
   "metadata": {},
   "source": [
    "### Download\n",
    "\n",
    "Download the required data: simulation outputs and the static polymer matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6ba8899",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(filename):\n",
    "    url = SERVICE_FILES_URL % filename\n",
    "    download = requests.get(url)\n",
    "    content = download.content.decode('utf-8')\n",
    "    reader = csv.DictReader(content.splitlines())\n",
    "    return list(reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f228d617",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_output_rows = download_file('web.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "305b41d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "polymer_rows = download_file('static_polymer_matrix.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b941c0",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Index Data\n",
    "\n",
    "Next, we index the downloaded data such that we can pull individual values for the approximation equation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a31115f",
   "metadata": {},
   "source": [
    "### Keying functions\n",
    "\n",
    "We look up values from dictionaries. To support that operation, these functions define the keys in which we index into those dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "142668e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_year_region_key(region, year):\n",
    "    pieces = [region, year]\n",
    "    pieces_str = map(lambda x: str(x).lower(), pieces)\n",
    "    return '\\t'.join(pieces_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39de2a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sector_key(region, year):\n",
    "    pieces = [region, year]\n",
    "    pieces_str = map(lambda x: str(x).lower(), pieces)\n",
    "    return '\\t'.join(pieces_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf81822",
   "metadata": {},
   "source": [
    "### Index fate propensities\n",
    "\n",
    "With these functions in place, we next determine the waste fate ratios which is the percent of waste in a region / year going to a specific fate like recycling. For example the recycling ratio for EU30 in 2035."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82f77640",
   "metadata": {},
   "outputs": [],
   "source": [
    "fate_propensities = {}\n",
    "\n",
    "for row in sim_output_rows:\n",
    "    year = row['year']\n",
    "\n",
    "    region = normalize_region(row['region'])\n",
    "    \n",
    "    fate_cols = FATES\n",
    "    total = sum(map(lambda x: float(row[x]), fate_cols))\n",
    "\n",
    "    individual_fates = map(lambda x: {'fate': x}, FATES)\n",
    "\n",
    "    fates_with_keys = map(lambda x: {\n",
    "        'fate': x['fate'],\n",
    "        'key': x['fate']\n",
    "    }, individual_fates)\n",
    "\n",
    "    fates_with_vals = map(lambda x: {\n",
    "        'fate': x['fate'],\n",
    "        'propensity': float(row[x['key']]) / total\n",
    "    }, fates_with_keys)\n",
    "\n",
    "    fates_with_vals_flat = map(lambda x: (\n",
    "        x['fate'],\n",
    "        x['propensity']\n",
    "    ), fates_with_vals)\n",
    "\n",
    "    key = get_year_region_key(region, year)\n",
    "    fate_propensities[key] = dict(fates_with_vals_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ff0198a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fate_propensity(region, year, fate):\n",
    "    return fate_propensities[get_year_region_key(region, year)][fate]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb3c046",
   "metadata": {},
   "source": [
    "### Index sector propensities\n",
    "\n",
    "Afterwards, we determine how much each sector makes up of the total consumption for a region / year. For example, this would include what percent of China consumption from 2050 is from transportation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8527a5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sector_propensities = {}\n",
    "\n",
    "for row in sim_output_rows:\n",
    "    year = row['year']\n",
    "    region = normalize_region(row['region'])\n",
    "\n",
    "    sector_cols = SECTORS\n",
    "    total = sum(map(lambda x: float(row[x]), sector_cols))\n",
    "\n",
    "    individual_sectors = map(lambda x: {'sector': x}, SECTORS)\n",
    "\n",
    "    sectors_with_keys = map(lambda x: {\n",
    "        'sector': x['sector'],\n",
    "        'key': x['sector']\n",
    "    }, individual_sectors)\n",
    "\n",
    "    sectors_with_vals = map(lambda x: {\n",
    "        'sector': x['sector'],\n",
    "        'propensity': float(row[x['key']]) / total\n",
    "    }, sectors_with_keys)\n",
    "\n",
    "    sectors_with_vals_flat = map(lambda x: (\n",
    "        x['sector'],\n",
    "        x['propensity']\n",
    "    ), sectors_with_vals)\n",
    "\n",
    "    key = get_year_region_key(region, year)\n",
    "    sector_propensities[key] = dict(sectors_with_vals_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9afe9ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sector_propensity(region, year, sector):\n",
    "    return sector_propensities[get_year_region_key(region, year)][sector]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291deafe",
   "metadata": {},
   "source": [
    "### Index total waste\n",
    "\n",
    "Additionally, we determine how much total waste is produced each year in each region across all fates. For example, the total waste generated in North Amercia in 2040."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "506458a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_waste = {}\n",
    "    \n",
    "for row in sim_output_rows:\n",
    "    year = row['year']\n",
    "    region = normalize_region(row['region'])\n",
    "    \n",
    "    fate_cols = FATES\n",
    "    total = sum(map(lambda x: float(row[x]), fate_cols))\n",
    "\n",
    "    key = get_year_region_key(region, year)\n",
    "    total_waste[key] = total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b7798b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_waste(region, year):\n",
    "    return total_waste[get_year_region_key(region, year)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb67c83",
   "metadata": {},
   "source": [
    "### Index sector polymers\n",
    "\n",
    "Finally, we determine how much each polymer makes up each sector within a region. For example, what percent of packaging is polystyrene in EU30 by mass. This is a static matrix so does not change year to year in the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a9c4246",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_polymer_percent(target):\n",
    "    return float(target.replace('%', '')) / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ff0b05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sector_polymers = {}\n",
    "    \n",
    "for row in polymer_rows:\n",
    "    region = normalize_region(row['region'])\n",
    "    sector = row['sector']\n",
    "\n",
    "    polymers_propensities_unnorm = dict(map(\n",
    "        lambda x: (x, parse_polymer_percent(row[x])),\n",
    "        POLYMERS\n",
    "    ))\n",
    "\n",
    "    total = sum(polymers_propensities_unnorm.values())\n",
    "\n",
    "    polymers_propensities = dict(map(\n",
    "        lambda x: (x[0], x[1] / total),\n",
    "        polymers_propensities_unnorm.items()\n",
    "    ))\n",
    "\n",
    "    sector_polymers[get_sector_key(region, sector)] = polymers_propensities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6eeaa689",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sector_polymer_propensity(region, sector, polymer):\n",
    "    return sector_polymers[get_sector_key(region, sector)][polymer]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f66e08a",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Perform calculations\n",
    "\n",
    "With the aforementioned consumption ($C$) approximation in mind, we use our now indexed data to estimate masses for each polymer $p$ in a region $r$ per sector $s$. This is the volume $v$ that saw the fate (such as incineration) $f$ in year $y$ as formalized below where volume is a function:\n",
    "\n",
    "$v(r, y, s, p, f) = W_{r,y} * \\frac{W_{f}}{W_{total}} * \\frac{C_{s}}{C_{total}} * \\frac{m_{p}}{m_{s}}$\n",
    "\n",
    "This effectively determines the following in order:\n",
    "\n",
    " - Total waste for a region / year combination.\n",
    " - Of the total waste, the waste going to the target end of life fate like landfill.\n",
    " - Of the fate waste, the amount from a given sector like construction.\n",
    " - Of the waste from the sector, the amount coming from a given polymer like LDPE.\n",
    "\n",
    "Finally, these estimations are summed across sectors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e137805a",
   "metadata": {},
   "source": [
    "### Calculate at the sector level\n",
    "\n",
    "We start by approximating the amount of each polymer in each sector going to each waste fate within a region / year combination like China 2040."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "68426e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_estimated_waste(region, year, sector, polymer, fate):\n",
    "    total_waste = get_total_waste(region, year)\n",
    "    \n",
    "    percent_in_fate = get_fate_propensity(region, year, fate)\n",
    "    waste_in_fate = total_waste * percent_in_fate\n",
    "    \n",
    "    percent_from_sector = get_sector_propensity(region, year, sector)\n",
    "    waste_in_fate_from_sector = waste_in_fate * percent_from_sector\n",
    "    \n",
    "    percent_from_polymer = get_sector_polymer_propensity(region, sector, polymer)\n",
    "    waste_polymer_in_fate_from_sector = percent_from_polymer * waste_in_fate_from_sector\n",
    "    \n",
    "    return waste_polymer_in_fate_from_sector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "993314ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "combinations_tuples = itertools.product(\n",
    "    REGIONS,\n",
    "    YEARS,\n",
    "    SECTORS,\n",
    "    POLYMERS,\n",
    "    FATES\n",
    ")\n",
    "\n",
    "combinations = map(lambda x: {\n",
    "    'region': x[0],\n",
    "    'year': x[1],\n",
    "    'sector': x[2],\n",
    "    'polymer': x[3],\n",
    "    'fate': x[4]\n",
    "}, combinations_tuples)\n",
    "\n",
    "combinations_with_vals = map(lambda x: {\n",
    "    'region': x['region'],\n",
    "    'year': x['year'],\n",
    "    'sector': x['sector'],\n",
    "    'polymer': x['polymer'],\n",
    "    'fate': x['fate'],\n",
    "    'group': '\\t'.join(map(lambda x: str(x), [\n",
    "        x['region'],\n",
    "        x['year'],\n",
    "        x['polymer'],\n",
    "        x['fate']\n",
    "    ])),\n",
    "    'amount': get_estimated_waste(\n",
    "        x['region'],\n",
    "        x['year'],\n",
    "        x['sector'],\n",
    "        x['polymer'],\n",
    "        x['fate']\n",
    "    )\n",
    "}, combinations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c3a76e",
   "metadata": {},
   "source": [
    "### Summarize across sectors\n",
    "\n",
    "We then sum across all sectors. For example, there will be four rows for Majority World in 2035: one for recycling, one for landfill, one for incineration, and one for mismanaged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5d7b3d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "individual_tuples = list(map(lambda x: (x['group'], x['amount']), combinations_with_vals))\n",
    "reduced_tuples = toolz.itertoolz.reduceby(\n",
    "    lambda x: x[0], lambda a, b: (a[0], a[1] + b[1]),\n",
    "    individual_tuples\n",
    ").values()\n",
    "reduced_thin_dicts = list(map(lambda x: {'group': x[0], 'amount': x[1]}, reduced_tuples))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938bb9cd",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Output\n",
    "\n",
    "Having generated this summarization, we write out the results to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "70b76c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_output_record(target_thin_dict):\n",
    "    pieces = target_thin_dict['group'].split('\\t')\n",
    "    return {\n",
    "        'region': pieces[0],\n",
    "        'year': pieces[1],\n",
    "        'polymer': pieces[2],\n",
    "        'fate': pieces[3],\n",
    "        'approximateAmount': target_thin_dict['amount']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c8ad37ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_records = map(make_output_record, reduced_thin_dicts)\n",
    "\n",
    "with open('polymer_eol_approximate.csv', 'w') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=['region', 'year', 'polymer', 'fate', 'approximateAmount'])\n",
    "    writer.writeheader()\n",
    "    writer.writerows(output_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1854b690",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Discussion\n",
    "\n",
    "Note that this method introduces a significant approximation. Due to lifecycle distributions, the sector ratios at time of waste generation may not be the same as if one were to project through time to get the prior sector ratios which generated the waste in question. Additionally, we do not have sector or product-specific EOL fate propensitives. Using proportionality absent additional information, this introduces further uncertainty into these estimates. Even so, this use of \"end of life year ratios\" may provide a sufficient estimation for many use cases in which these approximations are acceptable."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
